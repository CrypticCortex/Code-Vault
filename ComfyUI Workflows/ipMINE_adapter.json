{
  "last_node_id": 13,
  "last_link_id": 14,
  "nodes": [
    {
      "id": 12,
      "type": "PreviewImage",
      "pos": [
        1612,
        705
      ],
      "size": [
        210,
        246
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 13
        }
      ],
      "properties": {
        "Node name for S&R": "PreviewImage"
      }
    },
    {
      "id": 1,
      "type": "LoadImage",
      "pos": [
        -749,
        209
      ],
      "size": {
        "0": 315,
        "1": 314
      },
      "flags": {},
      "order": 0,
      "mode": 0,
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            1
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null,
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "LoadImage"
      },
      "widgets_values": [
        "test (1).webp",
        "image"
      ]
    },
    {
      "id": 5,
      "type": "PrepImageForClipVision",
      "pos": [
        -240,
        329
      ],
      "size": {
        "0": 315,
        "1": 106
      },
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 1
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            2
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "PrepImageForClipVision"
      },
      "widgets_values": [
        "LANCZOS",
        "center",
        0
      ]
    },
    {
      "id": 8,
      "type": "EmptyLatentImage",
      "pos": [
        610,
        1469
      ],
      "size": {
        "0": 315,
        "1": 106
      },
      "flags": {},
      "order": 1,
      "mode": 0,
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            10
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "EmptyLatentImage"
      },
      "widgets_values": [
        784,
        512,
        1
      ]
    },
    {
      "id": 11,
      "type": "VAEDecode",
      "pos": [
        1387,
        1040
      ],
      "size": {
        "0": 210,
        "1": 46
      },
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 12
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 11
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            13
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 2,
      "type": "CheckpointLoaderSimple",
      "pos": [
        8,
        778
      ],
      "size": {
        "0": 315,
        "1": 98
      },
      "flags": {},
      "order": 2,
      "mode": 0,
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            5
          ],
          "shape": 3,
          "slot_index": 0
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            6,
            7
          ],
          "shape": 3,
          "slot_index": 1
        },
        {
          "name": "VAE",
          "type": "VAE",
          "links": null,
          "shape": 3
        }
      ],
      "properties": {
        "Node name for S&R": "CheckpointLoaderSimple"
      },
      "widgets_values": [
        "picxReal_10.safetensors"
      ]
    },
    {
      "id": 3,
      "type": "IPAdapterModelLoader",
      "pos": [
        -55,
        12
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 3,
      "mode": 0,
      "outputs": [
        {
          "name": "IPADAPTER",
          "type": "IPADAPTER",
          "links": [
            4
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterModelLoader"
      },
      "widgets_values": [
        "ip-adapter_sd15.safetensors"
      ]
    },
    {
      "id": 13,
      "type": "CLIPVisionLoader",
      "pos": [
        -51,
        144
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 4,
      "mode": 0,
      "outputs": [
        {
          "name": "CLIP_VISION",
          "type": "CLIP_VISION",
          "links": [
            3
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPVisionLoader"
      },
      "widgets_values": [
        "CLIP-ViT-H-14-laion2B-s32B-b79K.safetensors"
      ]
    },
    {
      "id": 4,
      "type": "IPAdapterApply",
      "pos": [
        467,
        208
      ],
      "size": {
        "0": 315,
        "1": 258
      },
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "ipadapter",
          "type": "IPADAPTER",
          "link": 4
        },
        {
          "name": "clip_vision",
          "type": "CLIP_VISION",
          "link": 3
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 2
        },
        {
          "name": "model",
          "type": "MODEL",
          "link": 5
        },
        {
          "name": "attn_mask",
          "type": "MASK",
          "link": null
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            14
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "IPAdapterApply"
      },
      "widgets_values": [
        0.7000000000000001,
        0,
        "linear",
        0,
        1,
        false
      ]
    },
    {
      "id": 9,
      "type": "KSampler",
      "pos": [
        1001,
        846
      ],
      "size": {
        "0": 315,
        "1": 262
      },
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 14
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 8
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 9
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 10
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            12
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        40,
        "fixed",
        30,
        5,
        "ddpm",
        "ddim_uniform",
        1
      ]
    },
    {
      "id": 10,
      "type": "VAELoader",
      "pos": [
        997,
        1253
      ],
      "size": {
        "0": 315,
        "1": 58
      },
      "flags": {},
      "order": 5,
      "mode": 0,
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            11
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "VAELoader"
      },
      "widgets_values": [
        "vae-ft-mse-840000-ema-pruned.safetensors"
      ]
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        430,
        767
      ],
      "size": {
        "0": 400,
        "1": 200
      },
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 6
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            8
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "background to newyork city , same person, no change in cloth"
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        420,
        1037
      ],
      "size": {
        "0": 400,
        "1": 200
      },
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 7
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            9
          ],
          "shape": 3,
          "slot_index": 0
        }
      ],
      "properties": {
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "changed outfit, different pose, low quality , different camera angle"
      ]
    }
  ],
  "links": [
    [
      1,
      1,
      0,
      5,
      0,
      "IMAGE"
    ],
    [
      2,
      5,
      0,
      4,
      2,
      "IMAGE"
    ],
    [
      3,
      13,
      0,
      4,
      1,
      "CLIP_VISION"
    ],
    [
      4,
      3,
      0,
      4,
      0,
      "IPADAPTER"
    ],
    [
      5,
      2,
      0,
      4,
      3,
      "MODEL"
    ],
    [
      6,
      2,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      7,
      2,
      1,
      7,
      0,
      "CLIP"
    ],
    [
      8,
      6,
      0,
      9,
      1,
      "CONDITIONING"
    ],
    [
      9,
      7,
      0,
      9,
      2,
      "CONDITIONING"
    ],
    [
      10,
      8,
      0,
      9,
      3,
      "LATENT"
    ],
    [
      11,
      10,
      0,
      11,
      1,
      "VAE"
    ],
    [
      12,
      9,
      0,
      11,
      0,
      "LATENT"
    ],
    [
      13,
      11,
      0,
      12,
      0,
      "IMAGE"
    ],
    [
      14,
      4,
      0,
      9,
      0,
      "MODEL"
    ]
  ],
  "groups": [
    {
      "title": "Group",
      "bounding": [
        608,
        758,
        140,
        80
      ],
      "color": "#3f789e",
      "font_size": 24
    }
  ],
  "config": {},
  "extra": {},
  "version": 0.4
}